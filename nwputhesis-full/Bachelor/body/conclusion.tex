%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%   LaTeX File for Doctor (Master) Thesis of Tsinghua University
%   LaTeX + CJK     清华大学博士（硕士）论文模板
%   Based on Wang Tianshu's Template for XJTU
%	Version: 1.00
%   Last Update: 2003-09-12
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   Copyright 2002-2003  by  Lei Wang (BaconChina)       (bcpub@sina.com)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\renewcommand{\baselinestretch}{1.5}
\fontsize{12pt}{13pt}\selectfont

\chapter{全文总结}\label{conclusion}
\markboth{全文总结}{全文总结}
%\addcontentsline{toc}{chapter}{\hei 总结与展望}
\section{全文总结}
深度强化学习已经准备好在AI领域掀起一场革命。深度强化学习向建立对于真实世界具有高水平理解能力的全自主系统迈出了坚实的一步。当前，深度学习使强化学习有能力处理先前极为棘手的问题。本文通过应用深度强化学习在轮式机器人上，以实现轮式机器人的全自主战斗决策。主要做的工作如下：
\vspace{-10pt}
\begin{enumerate}
  \item 基于ROS，构建了轮式机器人的决策系统。通过将智能体agent部分与环境env部分解耦，实现了决策系统的模块化。
  \item 简述了强化学习的基本原理，介绍了基于值函数与策略搜索的强化学习基本算法。
  \item 基于Gazebo，搭建了轮式机器人仿真平台。
  \item 提出了多智能体异步的训练方法，解决了真实环境下的时延问题和采样速度问题。
  \item 实现并检验了DQN、DDPG和多智能体异步DDPG在仿真环境和真实环境下的训练和表现。
\end{enumerate}

\section{对未来工作的展望}
根据本文的分析，可以发现深度强化学习已经广泛应用于机器人控制任务，从简单运动到复杂操作和全自主移动机器人控制。然而，强化学习在真实世界中的实际应用通常需要超出学习算法本身的大量额外工程：
\vspace{-10pt}
\begin{enumerate}
  \item 机器人无法感知到真实世界的全貌，即机器人只能部分感知当前状态。
  \item 真实世界往往是奖励稀疏的，如何确定奖励函数是一个棘手的问题。
  \item 机器人在真实环境下存在着感知、通信和控制时延，这还会使得机器人无法。
\end{enumerate}

在未来的工作中，应该着重与解决这些问题。建立基于部分部分可观测马尔可夫决策过程的模型和算法；应该设计基于状态-动作对概率分布的奖励函数，使连续的状态-动作空间都能收到奖励或者惩罚信号；使用并发和分布式的方法，克服机器人在真实世界中训练的时延。

